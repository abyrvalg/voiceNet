{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-82d671f76905>, line 94)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-82d671f76905>\"\u001b[1;36m, line \u001b[1;32m94\u001b[0m\n\u001b[1;33m    .\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, architecture, files, model_path='./models/model.ckpt'):\n",
    "        self.model_path = model_path\n",
    "        self.architecture = architecture\n",
    "        self.transfer_fct = tf.nn.relu\n",
    "        self.files = files\n",
    "        self.loaded_model = False\n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, [None, architecture[\"input\"][0], architecture[\"input\"][1]])\n",
    "        \n",
    "        self._int_params(architecture)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        self.tf_saver = tf.train.Saver()\n",
    "        \n",
    "    def load_model(self, path=None):\n",
    "        self.tf_sess = tf.Session()\n",
    "        self.tf_sess.run(tf.global_variables_initializer())\n",
    "        self.tf_saver.restore(self.tf_sess, path if path != None else self.model_path)\n",
    "        self.loaded_model = True\n",
    "        \n",
    "    def normalize(self, x, get_mu_std=False):\n",
    "        mean, var = tf.nn.moments(x, axes=[0])\n",
    "        if(get_mu_std):\n",
    "            return (x - mean)/var, mean, var\n",
    "        else:\n",
    "            return (x - mean)/var\n",
    "\n",
    "    def restore(self, x, mu, var):\n",
    "        return (x*var + mu) - tf.reduce_min(x)\n",
    "        \n",
    "    def get_data_generator(self, file_path, frame_with, frame_count, batch_count, rand=False, get_meta=False, get_label=False):\n",
    "        if(type(file_path ) == str):\n",
    "            wave_read = [wave.open(file_path, \"rb\")]\n",
    "        else:\n",
    "            wave_read = []\n",
    "            for fp in file_path:\n",
    "                wave_read.append (wave.open(fp, \"rb\"))\n",
    "        if(get_meta):\n",
    "            meta = {\n",
    "                \"nframes\" : wave_read[0].getnframes(),\n",
    "                \"nchannels\" : wave_read[0].getnchannels(),\n",
    "                \"sampwidth\" : wave_read[0].getsampwidth(),\n",
    "                \"framerate\" : wave_read[0].getframerate()\n",
    "            }\n",
    "        for k in range(batch_count):\n",
    "            out = []\n",
    "            labels = []\n",
    "            for i in range(frame_count):\n",
    "                label = np.random.randint(len(wave_read))\n",
    "                chosen_file = wave_read[label]\n",
    "                if rand:\n",
    "                    chosen_file.setpos(np.random.randint(chosen_file.getnframes() - frame_with))           \n",
    "                if(get_label == True):\n",
    "                    labels.append(label)\n",
    "                out.append(np.fromstring(chosen_file.readframes(frame_with), np.uint16))\n",
    "            yield (out, labels) if(get_label == True) else out\n",
    "        for fr in wave_read:\n",
    "            fr.close()\n",
    "        yield meta if get_meta else None\n",
    "        \n",
    "    def create_loss(self, learning_rate):\n",
    "        normal_x = self.normalize(self.x)\n",
    "        z, z_mean, z_log_sigma_sq = self.encode(normal_x)\n",
    "        reconstruct = self.decode(z)\n",
    "        reconstr_loss = tf.reduce_mean(tf.pow(normal_x - reconstruct, 2))\n",
    "        latent_loss = -0.01 * tf.reduce_sum(1 + z_log_sigma_sq \n",
    "                                           - tf.square(z_mean) \n",
    "                                           - tf.exp(z_log_sigma_sq), 1)\n",
    "        \n",
    "        self.y =  tf.placeholder(tf.int32, [None])\n",
    "        class_loss = 0.1 * tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(logits=tf.matmul(z, self.params['class']['W']) \n",
    "                                                               + self.params['class']['b'], labels=self.y))\n",
    "        \n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss + class_loss)\n",
    "\n",
    "        self.optimizer = \\\n",
    "            tf.train.AdamOptimizer(learning_rate= learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def train(self, epoch_count, batch_size):      \n",
    "        data_generator = self.get_data_generator(self.files, self.architecture['input'], batch_size, epoch_count, True, False, True)\n",
    "              \n",
    "        if(self.loaded_model != True):\n",
    "            self.tf_sess = tf.Session()\n",
    "            self.tf_sess.run(tf.global_variables_initializer())\n",
    "        for i in range(epoch_count):\n",
    "            data = data_generator.__next__()\n",
    "            if(i % 50 == 0):\n",
    "                optimizer, cost = self.tf_sess.run([self.optimizer, self.cost], feed_dict={self.x: data[0], self.y: data[1]})\n",
    "                print(\"epoch:\" +str(i)+\", cost:\" +str(cost))\n",
    "            else:\n",
    "                optimizer = self.tf_sess.run(self.optimizer, feed_dict={self.x: data[0], self.y: data[1]})\n",
    "        .\n",
    "        data_generator.__next__()   \n",
    "        self.tf_saver.save(self.tf_sess, self.model_path)\n",
    "        \n",
    "    def encode(self, data):\n",
    "        z_mean, z_log_sigma_sq = self._forward_pass(self.params['rec'], data)\n",
    "        eps = tf.random_normal((tf.shape(data)[0], self.architecture['z']), 0, 1, \n",
    "                               dtype=tf.float32)\n",
    "        return tf.add(z_mean, tf.multiply(tf.sqrt(tf.exp(z_log_sigma_sq)), eps)), z_mean, z_log_sigma_sq\n",
    "    \n",
    "    def decode(self, data):\n",
    "        return self._forward_pass(self.params['gen'], data)\n",
    "            \n",
    "    def _int_params(self, architecture):\n",
    "        params = {\n",
    "            'rec' : {\n",
    "                'W' : {\n",
    "                    'layers' : [],\n",
    "                    'mean' : tf.Variable(xavier_init(architecture['rec'][-1], architecture['z'])),\n",
    "                    'log_sigma' : tf.Variable(xavier_init(architecture['rec'][-1], architecture['z']))\n",
    "                },\n",
    "                'b' : {\n",
    "                    'layers' : [],\n",
    "                    'mean' : tf.Variable(tf.zeros([architecture['z']], dtype=tf.float32)),\n",
    "                    'log_sigma' : tf.Variable(tf.zeros([architecture['z']], dtype=tf.float32))\n",
    "                }\n",
    "            },\n",
    "            'gen' : {\n",
    "                'W' : {\n",
    "                    'layers' : [],\n",
    "                    'mean' : tf.Variable(xavier_init(architecture['gen'][-1], architecture['z'])),\n",
    "                    'log_sigma' : tf.Variable(xavier_init(architecture['gen'][-1], architecture['z']))\n",
    "                },\n",
    "                'b' : {\n",
    "                    'layers' : [],\n",
    "                    'mean' : tf.Variable(tf.zeros([architecture['input']], dtype=tf.float32)),\n",
    "                    'log_sigma' : tf.Variable(tf.zeros([architecture['input']], dtype=tf.float32))\n",
    "                }\n",
    "            },\n",
    "            'class' : {\n",
    "                'W' : tf.Variable(xavier_init(architecture['z'], len(self.files))),\n",
    "                'b' : tf.Variable(tf.zeros([len(self.files)], dtype=tf.float32))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for i in range(len(architecture['rec'])):\n",
    "            if(isinstance(architecture[\"rec\"][i], list)):\n",
    "                print('capsule')\n",
    "            else:\n",
    "                params['rec']['W']['layers'].append(tf.Variable(xavier_init(\\\n",
    "                    architecture[\"input\"] if i==0 else architecture['rec'][i-1], \\\n",
    "                    architecture[\"rec\"][i])))            \n",
    "                params['rec']['b']['layers'].append(tf.Variable(tf.zeros([architecture[\"rec\"][i]], dtype=tf.float32)))  \n",
    "        params['rec']['W']['mean'] = tf.Variable(xavier_init(architecture['rec'][i], architecture['z']))\n",
    "        params['rec']['W']['log_sigma'] = tf.Variable(xavier_init(architecture['rec'][i], architecture['z']))\n",
    "        \n",
    "        for i in range(len(architecture['gen'])):\n",
    "            if(isinstance(architecture[\"gen\"][i], list)):\n",
    "                  \n",
    "            else:\n",
    "                params['gen']['W']['layers'].append(tf.Variable(xavier_init(\\\n",
    "                    architecture[\"z\"] if i==0 else architecture['gen'][i-1], \\\n",
    "                    architecture[\"gen\"][i])))            \n",
    "                params['gen']['b']['layers'].append(tf.Variable(tf.zeros([architecture[\"gen\"][i]], dtype=tf.float32)))\n",
    "             \n",
    "        params['gen']['W']['mean'] = tf.Variable(xavier_init(architecture['gen'][i], architecture['input']))\n",
    "        params['gen']['W']['log_sigma'] = tf.Variable(xavier_init(architecture['gen'][i], architecture['input']))\n",
    "        self.params = params\n",
    "        return params\n",
    "            \n",
    "    def _forward_pass(self, params, data):\n",
    "        current_val = data\n",
    "        for i in range(len(params['W']['layers'])):\n",
    "            current_val = self.transfer_fct(tf.add(tf.matmul(current_val, params['W']['layers'][i]), \n",
    "                                           params['b']['layers'][i]))\n",
    "        z_mean = tf.add(tf.matmul(current_val, params['W']['mean']), params['b']['mean'])\n",
    "        \n",
    "        if(params['W']['log_sigma']):\n",
    "            return (z_mean, tf.add(tf.matmul(current_val, params['W']['log_sigma']), params['b']['log_sigma']))\n",
    "        else:\n",
    "            return z_mean\n",
    "                \n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, get_mu_std=False):\n",
    "    ar = np.array(x)\n",
    "    mu = np.mean(ar)\n",
    "    std = np.std(ar)\n",
    "    if(get_mu_std):\n",
    "        return (ar - mu)/std, mu, std\n",
    "    else:\n",
    "        return (ar - mu)/std\n",
    "\n",
    "def restore(x, mu, std):\n",
    "    return np.array(x)*std + mu\n",
    "\n",
    "def get_file_frame(file_path, frame_with, frame_count, batch_count, rand=False, get_meta=False, get_label=False):\n",
    "    if(type(file_path ) == str):\n",
    "        wave_read = [wave.open(file_path, \"rb\")]\n",
    "    else:\n",
    "        wave_read = []\n",
    "        for fp in file_path:\n",
    "            wave_read.append (wave.open(fp, \"rb\"))\n",
    "    if(get_meta):\n",
    "        meta = {\n",
    "            \"nframes\" : wave_read[0].getnframes(),\n",
    "            \"nchannels\" : wave_read[0].getnchannels(),\n",
    "            \"sampwidth\" : wave_read[0].getsampwidth(),\n",
    "            \"framerate\" : wave_read[0].getframerate()\n",
    "        }\n",
    "    for k in range(batch_count):\n",
    "        out = []\n",
    "        labels = []\n",
    "        for i in range(frame_count):\n",
    "            label = np.random.randint(len(wave_read)) - 1\n",
    "            chosen_file = wave_read[label]\n",
    "            if rand:\n",
    "                chosen_file.setpos(np.random.randint(chosen_file.getnframes() - frame_with))           \n",
    "            if(get_label == True):\n",
    "                labels.append(label)\n",
    "            out.append(np.fromstring(chosen_file.readframes(frame_with), np.uint16))\n",
    "        yield [out, labels] if(get_label == True) else out\n",
    "    for fr in wave_read:\n",
    "        fr.close()\n",
    "    yield meta if get_meta else None\n",
    "    \n",
    "def write_wave(array, path, meta, mu=None, std=None):\n",
    "    unrolled = array.ravel()\n",
    "    writer = wave.open(path, \"wb\")\n",
    "    writer.setnframes(meta[\"nframes\"])\n",
    "    if(mu != None and std!=None):\n",
    "        unrolled = restore(unrolled, mu, std)\n",
    "    bytes_arr = np.rint(unrolled).astype(np.uint16).tobytes()\n",
    "    writer.setnchannels(meta[\"nchannels\"])\n",
    "    writer.setsampwidth(meta[\"sampwidth\"])\n",
    "    writer.setframerate(meta[\"framerate\"])\n",
    "    writer.writeframes(bytes_arr)\n",
    "    writer.close()\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "    \"\"\" Xavier initialization of network weights\"\"\"\n",
    "    # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), \n",
    "                             minval=low, maxval=high, \n",
    "                             dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-b7038f295249>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gauss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"01.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"03.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"04.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"05.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"06.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"07.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"11.wav\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"13.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"14.wav\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VNet' is not defined"
     ]
    }
   ],
   "source": [
    "vnet = VNet([[500,200], 300, 200, 100], \"gauss\")\n",
    "vnet.files= [\"01.wav\", \"03.wav\", \"04.wav\", \"05.wav\", \"06.wav\", \"07.wav\", \"11.wav\" ,\"13.wav\", \"14.wav\"]\n",
    "vnet.load_model()\n",
    "vnet.noise_std = 0\n",
    "vnet.init_vae(70)\n",
    "#rbm.train(get_file_frame, 500, 0.0000015, 700, 0.002, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_architecture = {\n",
    "    \"input\":(1000, 500),\n",
    "    \"rec\" : (700, 500, 300, 150),\n",
    "    \"gen\" : (100, 200, 500, 700),\n",
    "    \"z\" : 100\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(network_architecture, [\"01.wav\", \"03.wav\", \"04.wav\", \"05.wav\", \"06.wav\", \"07.wav\", \"11.wav\" ,\"13.wav\", \"14.wav\"])\n",
    "model.create_loss(0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '01.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bff59ccfd7f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#model.load_model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-35c185c0bb59>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epoch_count, batch_size)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-35c185c0bb59>\u001b[0m in \u001b[0;36mget_data_generator\u001b[1;34m(self, file_path, frame_with, frame_count, batch_count, rand, get_meta, get_label)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mwave_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mwave_read\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             meta = {\n",
      "\u001b[1;32mD:\\programs\\Continuum\\anaconda3\\envs\\tf\\lib\\wave.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\Continuum\\anaconda3\\envs\\tf\\lib\\wave.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# else, assume it is an open file object already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '01.wav'"
     ]
    }
   ],
   "source": [
    "#model.load_model()\n",
    "model.train(1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_wave(decoded, \"ress.wav\", meta, mu, std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_file_frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9aa545af1b26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#vnet = VNet([500, 300, 200, 100], \"gauss\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#vnet.load_model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_file_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"01.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfoo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_file_frame' is not defined"
     ]
    }
   ],
   "source": [
    "#vnet = VNet([500, 300, 200, 100], \"gauss\")\n",
    "#vnet.load_model()\n",
    "gen = get_file_frame(\"01.wav\", 500, 500, 1, False, True)\n",
    "foo = gen.__next__()  \n",
    "foo, mu, std = norm(foo, True)\n",
    "res = vnet.encode(foo) \n",
    "meta = gen.__next__()\n",
    "np.shape(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xavier_init' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e559eea2e9c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_architecture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"01.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"03.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"04.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"05.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"06.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"07.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"11.wav\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"13.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"14.wav\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-789d036afadf>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, architecture, files, model_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_int_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-789d036afadf>\u001b[0m in \u001b[0;36m_int_params\u001b[1;34m(self, architecture)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 'W' : {\n\u001b[0;32m    102\u001b[0m                     \u001b[1;34m'layers'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                     \u001b[1;34m'mean'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxavier_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rec'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[1;34m'log_sigma'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxavier_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rec'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 },\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xavier_init' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 150 and 700 for 'MatMul_4' (op: 'MatMul') with input shapes: [?,150], [700,1000].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 150 and 700 for 'MatMul_4' (op: 'MatMul') with input shapes: [?,150], [700,1000].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-f9de0962b5e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-dff3b9cb1283>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epoch_count, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mnormal_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_log_sigma_sq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mreconstruct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mreconstr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_x\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-dff3b9cb1283>\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_log_sigma_sq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rec'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         eps = tf.random_normal((self.batch_size, self.architecture['z']), 0, 1, \n\u001b[0;32m     91\u001b[0m                                dtype=tf.float32)\n",
      "\u001b[1;32m<ipython-input-31-dff3b9cb1283>\u001b[0m in \u001b[0;36m_forward_pass\u001b[1;34m(self, params, data)\u001b[0m\n\u001b[0;32m    155\u001b[0m                                            params['b']['layers'][i]))\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mz_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_sigma'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   1763\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[1;32m-> 1765\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   1452\u001b[0m   \"\"\"\n\u001b[0;32m   1453\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[1;32m-> 1454\u001b[1;33m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   1455\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    761\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    762\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2327\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2329\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2330\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2331\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1715\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1717\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1666\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1667\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1669\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\master\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 150 and 700 for 'MatMul_4' (op: 'MatMul') with input shapes: [?,150], [700,1000]."
     ]
    }
   ],
   "source": [
    "model.train(5, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = get_file_frame( [\"01.wav\", \"03.wav\", \"04.wav\", \"05.wav\", \"06.wav\", \"07.wav\", \"11.wav\" ,\"13.wav\", \"14.wav\"], 500, 500, 10000, rand=True, get_meta=False, get_label=False);\n",
    "def train(network_architecture, learning_rate=0.0001,\n",
    "          batch_size=500, training_epochs=10000, display_step=100):\n",
    "    vae = VariationalAutoencoder(network_architecture, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 batch_size=batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        \n",
    "        batch_xs= norm(gen.__next__());\n",
    "        # Fit training using batch data\n",
    "        cost = vae.partial_fit(batch_xs)\n",
    "        # Compute average loss\n",
    "        avg_cost += cost / batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(cost))\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#vae = train(network_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-0f29afe80012>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfoo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mwrite_wave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ress.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vae' is not defined"
     ]
    }
   ],
   "source": [
    "gen = get_file_frame(\"01.wav\", 500, 500, 1, False, True)\n",
    "foo = gen.__next__()  \n",
    "foo, mu, std = norm(foo, True)\n",
    "res = vae.reconstruct(foo)\n",
    "meta = gen.__next__()\n",
    "write_wave(res, \"ress.wav\", meta, mu, std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = get_file_frame(\"01.wav\", 50000, 5, 1, False, True)\n",
    "waveform = np.array(gen.__next__()).astype('float32')\n",
    "#signals = tf.placeholder(tf.float32, [None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functools\n",
    "\n",
    "frame_length = 400\n",
    "frame_step = 160\n",
    "stft = tf.contrib.signal.stft(waveform, frame_length, frame_step)\n",
    "t_magn = tf.abs(stft)\n",
    "argument = tf.angle(stft)\n",
    "inverse_stft = tf.contrib.signal.inverse_stft(\n",
    "    tf.cast(tf.complex(tf.cos(argument)*t_magn, tf.sin(argument)*t_magn), dtype = tf.complex64), frame_length, frame_step,\n",
    "    window_fn=tf.contrib.signal.inverse_stft_window_fn(frame_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sess = tf.Session()\n",
    "#tf_sess.as_default()\n",
    "spect = stft.eval(session = tf_sess)\n",
    "newWav = inverse_stft.eval(session = tf_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = gen.__next__()\n",
    "\n",
    "write_wave(newWav, \"ress.wav\", meta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.+0.j,  2.+0.j,  3.+0.j])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]).astype('complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2+1j)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 3+4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.abs(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "an = np.angle(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92729521800161219"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.sin(an)*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.cos(an)*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = r+im*1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0000000000000004+3.9999999999999996j)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
